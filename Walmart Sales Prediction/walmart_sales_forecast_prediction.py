# -*- coding: utf-8 -*-
"""Walmart Sales Forecast Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11KEo9ec5035eE-LSksjvLUeNIs1jjGG9
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker

import xgboost as xgb
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

"""# Data Understanding"""

df_feature = pd.read_csv("/content/drive/MyDrive/Master Degree/Self Project  Practice/Forecasting/Walmart Sales Forecast Prediction/Dataset/features.csv")
df_stores = pd.read_csv("/content/drive/MyDrive/Master Degree/Self Project  Practice/Forecasting/Walmart Sales Forecast Prediction/Dataset/stores.csv")
df_test = pd.read_csv("/content/drive/MyDrive/Master Degree/Self Project  Practice/Forecasting/Walmart Sales Forecast Prediction/Dataset/test.csv")
df_train = pd.read_csv("/content/drive/MyDrive/Master Degree/Self Project  Practice/Forecasting/Walmart Sales Forecast Prediction/Dataset/train.csv")

df_feature.describe()

df_feature.shape

df_feature.head()

df_train.head()

df_train.shape

df_train['Dept'].unique()

df_stores.head()

df_stores.shape

"""# Data cleaning
- Check missing value
- Merge the feature and store
"""

# Check missing value of features
df_feature.isnull().sum()

# Drop MarkDown as they have high number of NA
df_feature = df_feature.drop(['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5'], axis=1)

# Replace the NA of CPI and Unemployment with median
df_feature['CPI'].fillna(df_feature['CPI'].median(),inplace= True)
df_feature['Unemployment'].fillna(df_feature['Unemployment'].median(), inplace= True)

# Merge Dataset
df = df_feature.merge(df_stores, on='Store', how='left')

df_train.head()

df1 = df_train.merge(df, on=['Store','Date', 'IsHoliday'], how='left')

df1.shape

df1['IsHoliday'] = df1['IsHoliday'].apply(lambda x: 1 if x == True else 0)
df1['Type'] = df1['Type'].apply(lambda x: 1 if x == 'A' else (2 if x == 'B' else 3))

df1['Date'] = pd.to_datetime(df1['Date'])

df1.info()

def create_features(df):
  df['Date'] = pd.to_datetime(df['Date'])
  df['year'] = df['Date'].dt.year
  df['month'] = df['Date'].dt.month
  df['day'] = df['Date'].dt.day

  return df

create_features(df1)

"""# Visualization"""

df1.head(20)

fig, ax = plt.subplots(3,2, figsize=(20,15))

df1_list = ['Weekly_Sales',	'Temperature',	'Fuel_Price',	'CPI',	'Unemployment']

x = 0
y = 0

for i in df1_list:

  sns.lineplot(x='Date', y=i, data=df1, ax=ax[x,y])
  ax[x,y].set_title(f'Lineplot of {i}')
  ax[x,y].set_xlabel('Time')
  ax[x,y].set_ylabel(i)

  # Rotate x-ticks and set date format
  ax[x, y].tick_params(axis='x', rotation=45)
  ax[x, y].xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter('%Y-%m'))
  ax[x, y].xaxis.set_major_locator(plt.matplotlib.dates.MonthLocator())

  plt.tight_layout()
  y += 1
  if y == 2:
    y = 0
    x += 1

store_sales = df1.groupby('Store')['Weekly_Sales'].sum()

df_store_sales = store_sales.sort_values(ascending=False)

# Convert the sorted series to a DataFrame for easier plotting
df_store_sales = df_store_sales.reset_index()

# Plot barplot
plt.figure(figsize=(12, 6))
sns.barplot(x='Store', y='Weekly_Sales', data=df_store_sales, order=df_store_sales['Store'])

# Customize the y-tick format
def millions_formatter(x, pos):
    return f'{x / 1_000_000:.0f}M'

plt.gca().get_yaxis().set_major_formatter(mticker.FuncFormatter(millions_formatter))

plt.title('Total Sales by Store')
plt.xlabel('Store')
plt.ylabel('Total Sales')
plt.show()

"""# Train/test Split"""

df2 = df1.groupby('Date')['Weekly_Sales'].sum()
df2 = df2.reset_index()

number_date = len(df1['Date'].unique())

# 0.8 as split
date = number_date *0.8
date = int(date)
df1.iloc[date]['Date']

"""'2012-04-13' will be split of the train and test boarder"""

train = df2.iloc[:date]
test = df2.iloc[date:]

fig, ax = plt.subplots(figsize=(20,10))

sns.lineplot(x='Date', y='Weekly_Sales', data=train, color ='Blue',ax=ax)
sns.lineplot(x='Date', y='Weekly_Sales', data=test, color ='Red', ax=ax)
axline = ax.axvline(x=df1.iloc[date]['Date'], color='black', linestyle='--')

# Customize the y-tick format
def millions_formatter(x, pos):
    return f'{x / 1_000_000:.0f}M'

plt.gca().get_yaxis().set_major_formatter(mticker.FuncFormatter(millions_formatter))

plt.title('Total Sales')
plt.xlabel('Date')
plt.ylabel('Weekly Sales')
plt.show()

"""# Model"""

df1

feature = df1.drop(['Weekly_Sales', 'Date'], axis=1)
target = df1['Weekly_Sales']

X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size = 0.2, random_state =42)

# Model
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(),
    'Lasso Regression': Lasso(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor()
}

results= []

for model_name in models:
  model = models[model_name]
  model_train = model.fit(X_train, y_train)
  model_predict = model_train.predict(X_test)

  model_mse = mean_squared_error(y_test, model_predict)
  model_r2 = r2_score(y_test, model_predict)
  results.append((model_name, model_mse, model_r2))

print(results)

# Convert the list to a DataFrame
df_model_scores = pd.DataFrame(results, columns=['Model', 'Score', 'R_Score'])

# Sort values
df_model_scores = df_model_scores.sort_values(by='Score', ascending=True)
df_r2 = df_model_scores.sort_values(by='R_Score', ascending=False)

df_model_scores

fig, ax = plt.subplots(2,1, figsize=(10, 6))

# Create a bar plot

sns.barplot(x='Score', y='Model', data=df_model_scores, palette='viridis', ax=ax[0])
ax[0].set_title('Model Performance Comparison')
plt.xlabel('Score (Lower is Better)')
plt.ylabel('Model')

sns.barplot(x='R_Score', y='Model', data=df_r2, palette='viridis', ax=ax[1])
ax[1].set_title('Model Performance Comparison')
plt.xlabel('R_Score (Higher is Better)')
plt.ylabel('Model')

plt.tight_layout()

"""# Forecasting

## ARIMA
"""

from statsmodels.tsa.arima.model import ARIMA

weekly_sale = df1.groupby('Date')['Weekly_Sales'].sum().reset_index()

weekly_sale.set_index('Date',inplace =True)

weekly_sale

train = weekly_sale.iloc[:-52]
test = weekly_sale.iloc[-52:]

# Grid search parameters
best_aic = np.inf
best_order = None
best_model = None

# Define p, d, q values range
p_values = range(0, 8)
d_values = range(0, 3)
q_values = range(0, 8)

for p in p_values:
  for d in d_values:
    for q in q_values:
      try:
        model = ARIMA(train, order=(p, d, q))
        model_fit = model.fit()
        aic = model_fit.aic
        if aic < best_aic:
          best_aic = aic
          best_order = (p, d, q)
          best_model = model_fit
      except Exception as e:
        continue
        print(f"Error with order {p}, {d}, {q}: {e}")

print(f'Best order:{best_order} with best AIC: {best_aic}')

# Prediction

predictions = best_model.forecast(steps=len(test))

model_mse = mean_squared_error(test, predictions)
rmse = np.sqrt(model_mse)
model_r2 = r2_score(test, predictions)

print(f'RMSE: {rmse}')
print(f'R2: {model_r2}')

fig, ax = plt.subplots(figsize=(20,10))

sns.lineplot(x=train.index, y='Weekly_Sales', data=train, color ='Blue',ax=ax, label='Training')
sns.lineplot(x=test.index, y='Weekly_Sales', data=test, color ='Red',ax=ax, label='Testing')
sns.lineplot(x=test.index, y=predictions, color ='Orange', ax=ax, label='Prediction')
ax.set_title('ARIMA Weekly Sale Forecast')

"""The ARIMA model might not have captured the variation in the data as it showed flat orange line.

## SARIMA
"""

from statsmodels.tsa.statespace.sarimax import SARIMAX
from tqdm import tqdm

# Grid search parameter
best_aic = np.inf
best_order = None
best_seasonal_order = None
best_model = None

# Define a range of p, d, q values to try
p_values = range(0, 3)
d_values = range(0, 2)
q_values = range(0, 3)
P_values = range(0, 2)
D_values = range(0, 2)
Q_values = range(0, 2)
S = 52  # Assuming weekly seasonality

for p in tqdm(p_values):
    for d in d_values:
        for q in q_values:
            for P in P_values:
                for D in D_values:
                    for Q in Q_values:
                        try:
                            model = SARIMAX(train, order=(p, d, q), seasonal_order=(P, D, Q, S), enforce_stationarity=False, enforce_invertibility=False)
                            model_fit = model.fit(disp=False)
                            aic = model_fit.aic
                            if aic < best_aic:
                                best_aic = aic
                                best_order = (p, d, q)
                                best_seasonal_order = (P, D, Q, S)
                                best_model = model_fit
                        except Exception as e:
                            continue

print(f"Best SARIMA order: {best_order} with seasonal order: {best_seasonal_order} and AIC: {best_aic}")

# Walk-forward validation
predictions = []
for i in range(len(test)):
    train_data = weekly_sale.iloc[:-(52-i)]
    model = SARIMAX(train_data, order=best_order, seasonal_order=best_seasonal_order, enforce_stationarity=False, enforce_invertibility=False)
    model_fit = model.fit(disp=False)
    forecast = model_fit.forecast(steps=1)
    predictions.append(forecast.values[0])

# Evaluate the model
mse = mean_squared_error(test, predictions)
rmse = np.sqrt(mse)

print(f"RMSE for best SARIMA model: {rmse}")

fig, ax = plt.subplots(figsize=(20,10))

sns.lineplot(x=train.index, y='Weekly_Sales', data=train, color ='Blue',ax=ax, label='Training')
sns.lineplot(x=test.index, y='Weekly_Sales', data=test, color ='Red',ax=ax, label='Testing')
sns.lineplot(x=test.index, y=predictions, color ='Orange', ax=ax, label='Prediction')
ax.set_title('SARIMA Weekly Sale Forecast')

"""# Forecast Unseen Data"""

df_test['Weekly_Sales'] = np.nan

df_testset = df_test.groupby('Date')['Weekly_Sales'].sum().reset_index()

df_testset.set_index('Date',inplace =True)

train = weekly_sale
test = df_testset

predictions = []
from statsmodels.tsa.statespace.sarimax import SARIMAX
import matplotlib.pyplot as plt

# Train the SARIMA model on historical data
model = SARIMAX(train, order=best_order, seasonal_order=best_seasonal_order, enforce_stationarity=False, enforce_invertibility=False)
model_fit = model.fit(disp=False)

# Forecast
n_periods = len(test)
forecast = model_fit.forecast(steps=n_periods)

forecast = forecast.to_frame()
forecast.columns = ['predicted_mean']


fig, ax = plt.subplots(figsize=(20,10))

sns.lineplot(x=train.index, y='Weekly_Sales', data=train, color ='Blue',ax=ax, label='Training')
sns.lineplot(x=forecast.index, y='predicted_mean' ,data=forecast, color ='Orange', ax=ax, label='Prediction')
ax.set_title('SARIMA Weekly Sale Forecast')